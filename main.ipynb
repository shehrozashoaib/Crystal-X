{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as geom_nn\n",
    "from model import CrystalGraphConvNet  # Assuming ConvLayer is correctly imported from your cgcnn model file\n",
    "import os\n",
    "from data import CIFData\n",
    "from data import collate_pool, get_train_val_test_loader\n",
    "import csv\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_fea_len = 64\n",
    "hidden_size = 256\n",
    "batch_size = 256\n",
    "epochs = 200\n",
    "learning_rate = 0.001\n",
    "best_val_loss = float('inf')  # Initialize with a high value\n",
    "save_path = 'best_model.pth'\n",
    "n_conv = 8\n",
    "# Load dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CIFData(\"root_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader, val_loader, test_loader = get_train_val_test_loader(\n",
    "    dataset=dataset,\n",
    "    collate_fn=collate_pool,\n",
    "    batch_size=batch_size,\n",
    "    train_ratio=0.8,\n",
    "    num_workers=0,\n",
    "    val_ratio=0.1,\n",
    "    test_ratio=0.1,\n",
    "    pin_memory=True,\n",
    "    train_size=None,\n",
    "    val_size=None,\n",
    "    test_size=None,\n",
    "    return_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "class Normalizer(object):\n",
    "    \"\"\"Normalize a Tensor and restore it later. \"\"\"\n",
    "\n",
    "    def __init__(self, tensor):\n",
    "        \"\"\"tensor is taken as a sample to calculate the mean and std\"\"\"\n",
    "        self.mean = torch.mean(tensor)\n",
    "        self.std = torch.std(tensor)\n",
    "\n",
    "    def norm(self, tensor):\n",
    "        return (tensor - self.mean) / self.std\n",
    "\n",
    "    def denorm(self, normed_tensor):\n",
    "        return normed_tensor * self.std + self.mean\n",
    "\n",
    "    def state_dict(self):\n",
    "        return {'mean': self.mean,\n",
    "                'std': self.std}\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.mean = state_dict['mean']\n",
    "        self.std = state_dict['std']\n",
    "\n",
    "sample_data_list = [dataset[i] for i in\n",
    "                    sample(range(len(dataset)), 500)]\n",
    "_, sample_target, _ = collate_pool(sample_data_list)\n",
    "normalizer = Normalizer(sample_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures, _, _ = dataset[0]\n",
    "orig_atom_fea_len = structures[0].shape[-1]\n",
    "print(\"Original Atom Feature length: \",orig_atom_fea_len)\n",
    "nbr_fea_len = structures[1].shape[-1]\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "model = CrystalGraphConvNet(orig_atom_fea_len,nbr_fea_len, atom_fea_len,n_conv,hidden_size).cuda()\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "best_model = 0\n",
    "\n",
    "scheduler = MultiStepLR(optimizer, milestones=[100],\n",
    "                            gamma=0.1)\n",
    "\n",
    "best_mae_error = 1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(prediction, target):\n",
    "    \"\"\"\n",
    "    Computes the mean absolute error between prediction and target\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    prediction: torch.Tensor (N, 1)\n",
    "    target: torch.Tensor (N, 1)\n",
    "    \"\"\"\n",
    "    return torch.mean(torch.abs(target.to('cpu') - prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, normalizer, test=False):\n",
    "    \n",
    "    test_targets = []\n",
    "    test_preds = []\n",
    "    test_cif_ids = []\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    mae_errors = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for features, target, cif_id in val_loader:\n",
    "            atom_fea, nbr_fea, nbr_fea_idx, crystal_atom_idx, target = (features[0].cuda(), features[1].cuda(), \n",
    "                                                      features[2].cuda(), [crys_idx.cuda(non_blocking=True) for crys_idx in features[3]], target.cuda())\n",
    "            \n",
    "            target_normed = normalizer.norm(target)\n",
    "            target_var = target_normed.cuda(non_blocking=True)\n",
    "            output = model(atom_fea, nbr_fea, nbr_fea_idx, crystal_atom_idx)\n",
    "            loss = criterion(output, target_var)\n",
    "            \n",
    "            mae_error = mae(normalizer.denorm(output.data.cpu()), target)\n",
    "            mae_errors.update(mae_error, target.size(0))\n",
    "            if test:\n",
    "                test_pred = normalizer.denorm(output.data.cpu())\n",
    "                test_target = target\n",
    "                test_preds += test_pred.view(-1).tolist()\n",
    "                test_targets += test_target.view(-1).tolist()\n",
    "                test_cif_ids += cif_id\n",
    "    \n",
    "        \n",
    "            \n",
    "        if test:\n",
    "            star_label = \"**\"\n",
    "        else:\n",
    "            star_label = \"*\"\n",
    "        if True:\n",
    "            print(' {star} MAE {mae_errors.avg:.3f}'.format(star=star_label,\n",
    "                                                            mae_errors=mae_errors))\n",
    "        \n",
    "        if test:\n",
    "            return (mae_errors.avg,test_preds,test_targets,test_cif_ids)\n",
    "        else:\n",
    "            return (mae_errors.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, normalizer):\n",
    "    model.train()\n",
    "    mae_errors = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    for i, (input, target, _) in enumerate(train_loader):\n",
    "        atom_fea, nbr_fea, nbr_fea_idx, crystal_atom_idx, target = (input[0].cuda(), input[1].cuda(), \n",
    "                                                  input[2].cuda(), [crys_idx.cuda(non_blocking=True) for crys_idx in input[3]], target.cuda())\n",
    "        \n",
    "        target_normed = normalizer.norm(target)\n",
    "        target_var = target_normed.cuda(non_blocking=True)\n",
    "        \n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(atom_fea, nbr_fea, nbr_fea_idx, crystal_atom_idx)\n",
    "        loss = criterion(output, target_var)\n",
    "        \n",
    "        mae_error = mae(normalizer.denorm(output.data.cpu()), target)\n",
    "        losses.update(loss.data.cpu(), target.size(0))\n",
    "        mae_errors.update(mae_error, target.size(0))\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i%10==0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                          'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                          'MAE {mae_errors.val:.3f} ({mae_errors.avg:.3f})'.format(\n",
    "                        epoch, i, len(train_loader), loss=losses, mae_errors=mae_errors)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "save_path = 'best_model.pth'\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train(train_loader, model, criterion, optimizer, epoch, normalizer)\n",
    "\n",
    "    scheduler.step()\n",
    "    test_loss,test_preds,test_targets,test_cif_ids = validate(test_loader, model, criterion, normalizer, True)\n",
    "    if test_loss < best_val_loss:\n",
    "            best_val_loss = test_loss\n",
    "            best_model = model\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Best model saved with validation loss: {best_val_loss:.4f}, epoch: {epoch}\")\n",
    "            star_label = '**'\n",
    "            import csv\n",
    "            with open('test_results.csv', 'w') as f:\n",
    "                writer = csv.writer(f)\n",
    "                for cif_id, target, pred in zip(test_cif_ids, test_targets,\n",
    "                                                test_preds):\n",
    "                    writer.writerow((cif_id, target, pred))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
